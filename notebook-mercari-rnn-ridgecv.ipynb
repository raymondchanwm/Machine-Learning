{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36549872",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-07-21T14:20:37.040339Z",
     "iopub.status.busy": "2022-07-21T14:20:37.039207Z",
     "iopub.status.idle": "2022-07-21T14:20:37.053774Z",
     "shell.execute_reply": "2022-07-21T14:20:37.052254Z"
    },
    "papermill": {
     "duration": 0.024712,
     "end_time": "2022-07-21T14:20:37.056455",
     "exception": false,
     "start_time": "2022-07-21T14:20:37.031743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/mercari-price-suggestion-challenge/train.tsv.7z\n",
      "/kaggle/input/mercari-price-suggestion-challenge/test.tsv.7z\n",
      "/kaggle/input/mercari-price-suggestion-challenge/sample_submission_stg2.csv.zip\n",
      "/kaggle/input/mercari-price-suggestion-challenge/test_stg2.tsv.zip\n",
      "/kaggle/input/mercari-price-suggestion-challenge/sample_submission.csv.7z\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffa68edb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T14:20:37.068073Z",
     "iopub.status.busy": "2022-07-21T14:20:37.067799Z",
     "iopub.status.idle": "2022-07-21T14:20:58.639131Z",
     "shell.execute_reply": "2022-07-21T14:20:58.637972Z"
    },
    "papermill": {
     "duration": 21.579648,
     "end_time": "2022-07-21T14:20:58.641764",
     "exception": false,
     "start_time": "2022-07-21T14:20:37.062116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "\r\n",
      "p7zip is already the newest version (16.02+dfsg-7build1).\r\n",
      "p7zip set to manually installed.\r\n",
      "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\r\n",
      "\r\n",
      "7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\r\n",
      "p7zip Version 16.02 (locale=C.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.00GHz (50653),ASM,AES-NI)\r\n",
      "\r\n",
      "Scanning the drive for archives:\r\n",
      "  0M Scan ../input/mercari-price-suggestion-challenge/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1 file, 77912192 bytes (75 MiB)\r\n",
      "\r\n",
      "Extracting archive: ../input/mercari-price-suggestion-challenge/train.tsv.7z\r\n",
      "--\r\n",
      "Path = ../input/mercari-price-suggestion-challenge/train.tsv.7z\r\n",
      "Type = 7z\r\n",
      "Physical Size = 77912192\r\n",
      "Headers Size = 122\r\n",
      "Method = LZMA2:24\r\n",
      "Solid = -\r\n",
      "Blocks = 1\r\n",
      "\r\n",
      "  0%\b\b\b\b    \b\b\b\b  3% - train.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  7% - train.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 11% - train.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% - train.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 18% - train.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 21% - train.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 23% - train.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 27% - train.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 31% - train.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 34% - train.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 38% - train.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 42% - train.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 46% - train.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 50% - train.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 55% - train.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 59% - train.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 62% - train.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 67% - train.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 71% - train.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 75% - train.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 79% - train.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 83% - train.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 88% - train.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 92% - train.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 96% - train.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\r\n",
      "\r\n",
      "Size:       337809843\r\n",
      "Compressed: 77912192\r\n",
      "Archive:  ../input/mercari-price-suggestion-challenge/sample_submission_stg2.csv.zip\r\n",
      "  inflating: sample_submission_stg2.csv  \r\n",
      "Archive:  ../input/mercari-price-suggestion-challenge/test_stg2.tsv.zip\r\n",
      "  inflating: test_stg2.tsv           \r\n",
      "\r\n",
      "7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\r\n",
      "p7zip Version 16.02 (locale=C.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.00GHz (50653),ASM,AES-NI)\r\n",
      "\r\n",
      "Scanning the drive for archives:\r\n",
      "  0M Scan ../input/mercari-price-suggestion-challenge/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1 file, 35617013 bytes (34 MiB)\r\n",
      "\r\n",
      "Extracting archive: ../input/mercari-price-suggestion-challenge/test.tsv.7z\r\n",
      "--\r\n",
      "Path = ../input/mercari-price-suggestion-challenge/test.tsv.7z\r\n",
      "Type = 7z\r\n",
      "Physical Size = 35617013\r\n",
      "Headers Size = 122\r\n",
      "Method = LZMA2:24\r\n",
      "Solid = -\r\n",
      "Blocks = 1\r\n",
      "\r\n",
      "  0%\b\b\b\b    \b\b\b\b  8% - test.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% - test.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 26% - test.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35% - test.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 44% - test.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 52% - test.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 61% - test.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 70% - test.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 79% - test.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 88% - test.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 97% - test.tsv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\r\n",
      "\r\n",
      "Size:       154222160\r\n",
      "Compressed: 35617013\r\n"
     ]
    }
   ],
   "source": [
    "!apt-get install p7zip\n",
    "!p7zip -d -f -k ../input/mercari-price-suggestion-challenge/train.tsv.7z\n",
    "!unzip -o ../input/mercari-price-suggestion-challenge/sample_submission_stg2.csv.zip\n",
    "!unzip -o ../input/mercari-price-suggestion-challenge/test_stg2.tsv.zip\n",
    "!p7zip -d -f -k ../input/mercari-price-suggestion-challenge/test.tsv.7z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd85c82e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T14:20:58.661106Z",
     "iopub.status.busy": "2022-07-21T14:20:58.660790Z",
     "iopub.status.idle": "2022-07-21T14:21:07.063501Z",
     "shell.execute_reply": "2022-07-21T14:21:07.062448Z"
    },
    "papermill": {
     "duration": 8.415538,
     "end_time": "2022-07-21T14:21:07.066290",
     "exception": false,
     "start_time": "2022-07-21T14:20:58.650752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1482535, 8) (693359, 7)\n",
      "CPU times: user 7.35 s, sys: 825 ms, total: 8.17 s\n",
      "Wall time: 8.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#preprocessing\n",
    "#show time consumed\n",
    "from datetime import datetime\n",
    "start_real = datetime.now() #start measuring the time used\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#read training and testing data\n",
    "train_df = pd.read_table('train.tsv')\n",
    "test_df = pd.read_table('test.tsv')\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f34bcbef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T14:21:07.095789Z",
     "iopub.status.busy": "2022-07-21T14:21:07.095289Z",
     "iopub.status.idle": "2022-07-21T14:21:07.373318Z",
     "shell.execute_reply": "2022-07-21T14:21:07.372364Z"
    },
    "papermill": {
     "duration": 0.295585,
     "end_time": "2022-07-21T14:21:07.376138",
     "exception": false,
     "start_time": "2022-07-21T14:21:07.080553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1481661, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.drop(train_df[(train_df.price < 3.0)].index)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2200443",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T14:21:07.405671Z",
     "iopub.status.busy": "2022-07-21T14:21:07.405178Z",
     "iopub.status.idle": "2022-07-21T14:21:17.826330Z",
     "shell.execute_reply": "2022-07-21T14:21:17.824704Z"
    },
    "papermill": {
     "duration": 10.438772,
     "end_time": "2022-07-21T14:21:17.829208",
     "exception": false,
     "start_time": "2022-07-21T14:21:07.390436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.3 s, sys: 49.8 ms, total: 10.4 s\n",
      "Wall time: 10.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#confirm word count of item's name and description\n",
    "\n",
    "def wordCount(text):\n",
    "    \"\"\"\n",
    "    Parameter\n",
    "        text(str): item's name and description\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        if text == 'No description yet':\n",
    "            return 0 #no word then reutn 0\n",
    "        else:\n",
    "            text = text.lower()\n",
    "            words = [w for w in text.split(' ')] #split by space\n",
    "            return len(words)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "#record len of 'name' in 'name_len'\n",
    "train_df['name_len'] = train_df['name'].apply(lambda x: wordCount(x))\n",
    "test_df['name_len'] = test_df['name'].apply(lambda x: wordCount(x))\n",
    "\n",
    "#record len of 'description' in 'desc_len'\n",
    "train_df['desc_len'] = train_df['item_description'].apply(lambda x: wordCount(x))\n",
    "test_df['desc_len'] = test_df['item_description'].apply(lambda x: wordCount(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85a46311",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T14:21:17.848171Z",
     "iopub.status.busy": "2022-07-21T14:21:17.847890Z",
     "iopub.status.idle": "2022-07-21T14:21:17.880959Z",
     "shell.execute_reply": "2022-07-21T14:21:17.879843Z"
    },
    "papermill": {
     "duration": 0.045448,
     "end_time": "2022-07-21T14:21:17.883817",
     "exception": false,
     "start_time": "2022-07-21T14:21:17.838369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.5 ms, sys: 0 ns, total: 28.5 ms\n",
      "Wall time: 27.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "import numpy as np\n",
    "\n",
    "#log transform\n",
    "train_df['target'] = np.log1p(train_df.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4925f0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T14:21:17.903336Z",
     "iopub.status.busy": "2022-07-21T14:21:17.903057Z",
     "iopub.status.idle": "2022-07-21T14:21:25.013680Z",
     "shell.execute_reply": "2022-07-21T14:21:25.012605Z"
    },
    "papermill": {
     "duration": 7.123159,
     "end_time": "2022-07-21T14:21:25.016527",
     "exception": false,
     "start_time": "2022-07-21T14:21:17.893368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.72 s, sys: 385 ms, total: 7.1 s\n",
      "Wall time: 7.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def split_cat(text):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        text(str): category's name\n",
    "            -split by '/'\n",
    "            -if data not exist, return 'no label'\n",
    "    \"\"\"\n",
    "\n",
    "    try: return text.split('/')\n",
    "    except: return ('No Label', 'No Label', 'No Label')\n",
    "\n",
    "#split training data\n",
    "train_df['subcat_0'] , train_df['subcat_1'], train_df['subcat_2'] = \\\n",
    "    zip(* train_df['category_name'].apply(lambda x: split_cat(x)))\n",
    "#test data\n",
    "test_df['subcat_0'], test_df['subcat_1'], test_df['subcat_2'] = \\\n",
    "    zip(* test_df['category_name'].apply(lambda x: split_cat(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49ed295f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T14:21:25.049243Z",
     "iopub.status.busy": "2022-07-21T14:21:25.048901Z",
     "iopub.status.idle": "2022-07-21T14:21:56.640735Z",
     "shell.execute_reply": "2022-07-21T14:21:56.639631Z"
    },
    "papermill": {
     "duration": 31.61791,
     "end_time": "2022-07-21T14:21:56.651365",
     "exception": false,
     "start_time": "2022-07-21T14:21:25.033455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632336\n",
      "137342\n",
      "295525\n",
      "64154\n",
      "CPU times: user 31 s, sys: 502 ms, total: 31.5 s\n",
      "Wall time: 31.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#concat train and test\n",
    "full_set = pd.concat([train_df, test_df])\n",
    "\n",
    "#find all brand name and create list of brand\n",
    "all_brands = set(full_set['brand_name'].values)\n",
    "\n",
    "#replace missing values in 'brand_name' (NaN) by 'missing'\n",
    "train_df['brand_name'].fillna(value = 'missing', inplace = True)\n",
    "test_df['brand_name'].fillna(value = 'missing',  inplace = True)\n",
    "\n",
    "#get number of missing value of train data\n",
    "train_premissing = len(train_df.loc[train_df['brand_name'] == 'missing'])\n",
    "\n",
    "#get number of missing value of test data\n",
    "test_premissing = len(test_df.loc[test_df['brand_name'] == 'missing'])\n",
    "\n",
    "def brandFinder(line):\n",
    "\n",
    "    brand = line[0] #index [0] to be brand name\n",
    "    name = line[1] #index [1] to be item name\n",
    "    namesplit = name.split(' ') #split by space\n",
    "\n",
    "    if brand == 'missing': #is missing\n",
    "        for x in namesplit: #get item name from single word\n",
    "            if x in all_brands: #if item name (single word) in brand list, return item name\n",
    "                return name\n",
    "    if name in all_brands: #not missing\n",
    "        return name #return item name\n",
    "    \n",
    "    return brand #if not in brand list\n",
    "\n",
    "#replace brand name\n",
    "train_df['brand_name'] = train_df[['brand_name','name']].apply(brandFinder, axis = 1)\n",
    "test_df['brand_name'] = test_df[['brand_name', 'name']].apply(brandFinder, axis =1)\n",
    "\n",
    "#get number of missing value after replacement\n",
    "train_len = len(train_df.loc[train_df['brand_name'] == 'missing'])\n",
    "test_len = len(test_df.loc[test_df['brand_name'] == 'missing'])\n",
    "train_found = train_premissing - train_len\n",
    "test_found = test_premissing - test_len\n",
    "print(train_premissing)\n",
    "print(train_found)\n",
    "print(test_premissing)\n",
    "print(test_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "287b83cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T14:21:56.669840Z",
     "iopub.status.busy": "2022-07-21T14:21:56.669548Z",
     "iopub.status.idle": "2022-07-21T14:21:59.279921Z",
     "shell.execute_reply": "2022-07-21T14:21:59.278483Z"
    },
    "papermill": {
     "duration": 2.622068,
     "end_time": "2022-07-21T14:21:59.281921",
     "exception": false,
     "start_time": "2022-07-21T14:21:56.659853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \t 1466844 examples\n",
      "Validating \t: 14817 examples\n",
      "Testing: \t 693359 examples\n",
      "CPU times: user 2.16 s, sys: 169 ms, total: 2.33 s\n",
      "Wall time: 2.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#separate train and test dataframe in 99:1\n",
    "#since 1% is already large enough (over 10k)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc #garbage collection\n",
    "train_dfs, dev_dfs = train_test_split(train_df,\n",
    "                                      random_state = 123,\n",
    "                                      train_size = 0.99,\n",
    "                                      test_size = 0.01,)\n",
    "\n",
    "n_trains = train_dfs.shape[0] #shape of test data\n",
    "n_devs = dev_dfs.shape[0] #shape of validation data\n",
    "n_tests = test_df.shape[0] #shape of test data\n",
    "\n",
    "print('Training: \\t', n_trains, 'examples')\n",
    "print('Validating \\t:', n_devs, 'examples')\n",
    "print('Testing: \\t', n_tests, 'examples')\n",
    "del train_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8b26a81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T14:21:59.301212Z",
     "iopub.status.busy": "2022-07-21T14:21:59.300455Z",
     "iopub.status.idle": "2022-07-21T14:22:01.584711Z",
     "shell.execute_reply": "2022-07-21T14:22:01.582522Z"
    },
    "papermill": {
     "duration": 2.296794,
     "end_time": "2022-07-21T14:22:01.587576",
     "exception": false,
     "start_time": "2022-07-21T14:21:59.290782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.16 s, sys: 116 ms, total: 2.28 s\n",
      "Wall time: 2.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Concat training, validating and testing data\n",
    "full_df = pd.concat([train_dfs, dev_dfs, test_df])\n",
    "\n",
    "def fill_missing_values(df):\n",
    "    #category of item\n",
    "    df.category_name.fillna(value = 'missing', inplace = True)\n",
    "    #brand name\n",
    "    df.brand_name.fillna(value = 'missing', inplace = True)\n",
    "    #description\n",
    "    df.item_description.fillna(value = 'missing', inplace = True)\n",
    "    \n",
    "    #description (No description yet -> missing)\n",
    "    df.item_description.replace('No description yet', \n",
    "                                'missing', inplace = True)\n",
    "    return df\n",
    "\n",
    "full_df = fill_missing_values(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c312f7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T14:22:01.606568Z",
     "iopub.status.busy": "2022-07-21T14:22:01.606260Z",
     "iopub.status.idle": "2022-07-21T14:22:10.717330Z",
     "shell.execute_reply": "2022-07-21T14:22:10.716309Z"
    },
    "papermill": {
     "duration": 9.122742,
     "end_time": "2022-07-21T14:22:10.719438",
     "exception": false,
     "start_time": "2022-07-21T14:22:01.596696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prcessing categorical data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "print('Prcessing categorical data')\n",
    "\n",
    "#create LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "#encode 'category_name', 'brand_name'\n",
    "le.fit(full_df.category_name)\n",
    "full_df['category'] = le.transform(full_df.category_name)\n",
    "\n",
    "le.fit(full_df.brand_name)\n",
    "full_df.brand_name = le.transform(full_df.brand_name)\n",
    "\n",
    "le.fit_transform(full_df.subcat_0)\n",
    "full_df.subcat_0 = le.transform(full_df.subcat_0)\n",
    "le.fit_transform(full_df.subcat_1)\n",
    "full_df.subcat_1 = le.transform(full_df.subcat_1)\n",
    "le.fit_transform(full_df.subcat_2)\n",
    "full_df.subcat_2 = le.transform(full_df.subcat_2)\n",
    "\n",
    "\n",
    "del le\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9d42216",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T14:22:10.740742Z",
     "iopub.status.busy": "2022-07-21T14:22:10.739131Z",
     "iopub.status.idle": "2022-07-21T14:25:35.421025Z",
     "shell.execute_reply": "2022-07-21T14:25:35.419843Z"
    },
    "papermill": {
     "duration": 204.70323,
     "end_time": "2022-07-21T14:25:35.432297",
     "exception": false,
     "start_time": "2022-07-21T14:22:10.729067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming text data to sequence data\n",
      "Sequences shape,  (6525060,)\n",
      "Fitting tokenizer\n",
      "Transforming text to sequences\n",
      "CPU times: user 3min 19s, sys: 2.15 s, total: 3min 21s\n",
      "Wall time: 3min 24s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#apply label encoding to the concatenated df\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "#concat list of (item description, item name, item category_name)\n",
    "print(\"Transforming text data to sequence data\")\n",
    "raw_text = np.hstack([full_df.item_description.str.lower(),\n",
    "                     full_df.name.str.lower(),\n",
    "                     full_df.category_name.str.lower(),])\n",
    "\n",
    "print('Sequences shape, ',raw_text.shape)\n",
    "\n",
    "print(\"Fitting tokenizer\")\n",
    "tok_raw = Tokenizer()\n",
    "tok_raw.fit_on_texts(raw_text)\n",
    "print(\"Transforming text to sequences\")\n",
    "full_df['seq_item_description'] = tok_raw.texts_to_sequences(\\\n",
    "    full_df.item_description.str.lower())\n",
    "full_df['seq_name'] = tok_raw.texts_to_sequences(\\\n",
    "    full_df.name.str.lower())\n",
    "\n",
    "del tok_raw\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5becdad6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T14:25:35.454666Z",
     "iopub.status.busy": "2022-07-21T14:25:35.454117Z",
     "iopub.status.idle": "2022-07-21T14:25:36.415262Z",
     "shell.execute_reply": "2022-07-21T14:25:36.414243Z"
    },
    "papermill": {
     "duration": 0.974666,
     "end_time": "2022-07-21T14:25:36.417863",
     "exception": false,
     "start_time": "2022-07-21T14:25:35.443197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#unify the size of item name, item description and item category\n",
    "MAX_NAME_SEQ = 10       #item name size limit\n",
    "MAX_ITEM_DESC_SEQ = 75  #item description size limit\n",
    "MAX_CATEGORY_SEQ = 8    #item category size limit\n",
    "\n",
    "#define embedding layer input size\n",
    "\n",
    "#item name and item description word size: limit + 100\n",
    "MAX_TEXT = np.max(\n",
    "    [np.max(full_df.seq_name.max()),\n",
    "     np.max(full_df.seq_item_description.max())]) + 100\n",
    "\n",
    "#item category word size = limit + 1\n",
    "MAX_CATEGORY = np.max(full_df.category.max()) +1\n",
    "\n",
    "#brand word size = limit + 1\n",
    "MAX_BRAND = np.max(full_df.brand_name.max()) +1\n",
    "\n",
    "#item condition = limit + 1\n",
    "MAX_CONDITION = np.max(full_df.item_condition_id.max()) +1\n",
    "\n",
    "#Description word  length = limit + 1\n",
    "MAX_DESC_LEN = np.max(full_df.desc_len.max()) +1\n",
    "\n",
    "#item name length = limit + 1\n",
    "MAX_NAME_LEN = np.max(full_df.name_len.max()) + 1\n",
    "\n",
    "#subcat word = limit + 1\n",
    "MAX_SUBCAT_0 = np.max(full_df.subcat_0.max()) + 1\n",
    "MAX_SUBCAT_1 = np.max(full_df.subcat_1.max()) + 1\n",
    "MAX_SUBCAT_2 = np.max(full_df.subcat_2.max()) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec254b92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T14:25:36.440328Z",
     "iopub.status.busy": "2022-07-21T14:25:36.439964Z",
     "iopub.status.idle": "2022-07-21T14:25:59.356241Z",
     "shell.execute_reply": "2022-07-21T14:25:59.355094Z"
    },
    "papermill": {
     "duration": 22.929271,
     "end_time": "2022-07-21T14:25:59.358228",
     "exception": false,
     "start_time": "2022-07-21T14:25:36.428957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.5 s, sys: 334 ms, total: 22.9 s\n",
      "Wall time: 22.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def get_rnn_data(dataset):\n",
    "    \"\"\"\n",
    "    Parameter:\n",
    "        dataset: all data\n",
    "    \"\"\"\n",
    "    X ={\n",
    "        #item name\n",
    "        #MAX_NAME_SEQ = 10\n",
    "        'name' : pad_sequences(dataset.seq_name,\n",
    "                                maxlen = MAX_NAME_SEQ),\n",
    "\n",
    "        #item description\n",
    "        'item_desc': pad_sequences(dataset.seq_item_description,\n",
    "                                   maxlen = MAX_ITEM_DESC_SEQ),\n",
    "        #brand_name\n",
    "        'brand_name': np.array(dataset.brand_name),\n",
    "\n",
    "        #item condition\n",
    "        'item_condition': np.array(dataset.item_condition_id,),\n",
    "\n",
    "        #num_vars\n",
    "        'num_vars': np.array(dataset[['shipping']]),\n",
    "\n",
    "        #item description\n",
    "        'desc_len':np.array(dataset[['desc_len']]),\n",
    "\n",
    "        #item name\n",
    "        'name_len': np.array(dataset[['name_len']]),\n",
    "\n",
    "        #item subcat\n",
    "        'subcat_0': np.array(dataset.subcat_0),\n",
    "        'subcat_1': np.array(dataset.subcat_1),\n",
    "        'subcat_2': np.array(dataset.subcat_2)\n",
    "    }\n",
    "\n",
    "    return X\n",
    "    \n",
    "#training data: index 0 to training data index\n",
    "train = full_df[:n_trains]\n",
    "\n",
    "#validation\n",
    "dev = full_df[n_trains:n_trains + n_devs]\n",
    "\n",
    "#testing data\n",
    "test = full_df[n_trains + n_devs: ]\n",
    "\n",
    "#get training dict\n",
    "X_train = get_rnn_data(train)\n",
    "#transform training item price from 1D to 2D\n",
    "#(1466844 -> (1466844,1))\n",
    "Y_train = train.target.values.reshape(-1, 1)\n",
    "\n",
    "#get validation dict\n",
    "X_dev = get_rnn_data(dev)\n",
    "Y_dev = dev.target.values.reshape(-1,1)\n",
    "\n",
    "#get testing dict\n",
    "X_test = get_rnn_data(test)\n",
    "\n",
    "del full_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "937f716c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T14:25:59.379344Z",
     "iopub.status.busy": "2022-07-21T14:25:59.378764Z",
     "iopub.status.idle": "2022-07-21T14:26:03.514502Z",
     "shell.execute_reply": "2022-07-21T14:26:03.513561Z"
    },
    "papermill": {
     "duration": 4.148777,
     "end_time": "2022-07-21T14:26:03.516687",
     "exception": false,
     "start_time": "2022-07-21T14:25:59.367910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 14:25:59.501482: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-21 14:25:59.610015: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-21 14:25:59.610850: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-21 14:25:59.612998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-21 14:25:59.613331: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-21 14:25:59.614293: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-21 14:25:59.615347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-21 14:26:01.502211: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-21 14:26:01.503276: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-21 14:26:01.503983: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-21 14:26:01.504591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
      "/opt/conda/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "brand_name (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_condition (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_len (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "name_len (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "subcat_0 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "subcat_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "subcat_2 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_desc (InputLayer)          [(None, 75)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "name (InputLayer)               [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 10)        1791400     brand_name[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 5)         30          item_condition[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 5)         1230        desc_len[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 5)         90          name_len[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 1, 10)        110         subcat_0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 1, 10)        1140        subcat_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 1, 10)        8830        subcat_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 75, 60)       19321200    item_desc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 10, 20)       6440400     name[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 10)           0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 5)            0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 5)            0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 5)            0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 10)           0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 10)           0           embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 10)           0           embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "gru (GRU)                       (None, 16)           3744        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     (None, 8)            720         embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "num_vars (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 80)           0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "                                                                 gru[0][0]                        \n",
      "                                                                 gru_1[0][0]                      \n",
      "                                                                 num_vars[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          41472       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 512)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          131328      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          32896       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           8256        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 64)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            65          dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 27,782,911\n",
      "Trainable params: 27,782,911\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5513"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dropout, Dense, Embedding, Flatten\n",
    "from tensorflow.keras.layers import concatenate, GRU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "np.random.seed(123) #random number\n",
    "#define rmse, use to predict situation\n",
    "#use this rmse after log transformation\n",
    "def rmsle(Y, Y_pred):\n",
    "    assert Y.shape == Y_pred\n",
    "    return np.sqrt(np.mean(np.Square(Y_pred - Y)))\n",
    "\n",
    "def new_rnn_model(lr = 0.001, decay = 0.0):\n",
    "    \"\"\"\n",
    "    create RNN model\n",
    "    Parameters:\n",
    "        lr: learning rate\n",
    "        decay: decay of learning rate\n",
    "    \"\"\"\n",
    "\n",
    "    #input layer\n",
    "    #item name, description, brand name, item condition, num_vars\n",
    "    name        = Input(shape = [X_train['name'].shape[1]],\n",
    "                                 name = 'name')\n",
    "    item_desc   = Input(shape = [X_train['item_desc'].shape[1]],\n",
    "                                 name = 'item_desc')\n",
    "    brand_name  = Input(shape = [1], name = 'brand_name')\n",
    "    item_condition = Input(shape = [1], name = 'item_condition')\n",
    "    num_vars    = Input(shape = [X_train['num_vars'].shape[1]],\n",
    "                                 name = 'num_vars')\n",
    "    #item  name wording, item description wording\n",
    "    name_len    = Input(shape = [1], name = 'name_len')\n",
    "    desc_len    = Input(shape = [1], name = 'desc_len')\n",
    "\n",
    "    #item subcat\n",
    "    subcat_0    = Input(shape = [1], name = 'subcat_0')\n",
    "    subcat_1    = Input(shape = [1], name = 'subcat_1')\n",
    "    subcat_2    = Input(shape = [1], name = 'subcat_2')\n",
    "\n",
    "    #embedding layers\n",
    "    #item name embedding: input length = (MAX_TEXT), output = (20)\n",
    "    ebd_name = Embedding(MAX_TEXT, 20)(name)\n",
    "    #item description embedding: input length = (MAX_TEXT), output = (60)\n",
    "    ebd_item_desc = Embedding(MAX_TEXT, 60)(item_desc)\n",
    "    #embedding so on\n",
    "    ebd_brand_name = Embedding(MAX_BRAND, 10)(brand_name)\n",
    "    ebd_item_condition = Embedding(MAX_CONDITION, 5)(item_condition)\n",
    "    ebd_name_len = Embedding(MAX_NAME_LEN, 5)(name_len)\n",
    "    ebd_desc_len = Embedding(MAX_DESC_LEN, 5)(desc_len)\n",
    "    ebd_subcat_0 = Embedding(MAX_SUBCAT_0, 10)(subcat_0)\n",
    "    ebd_subcat_1 = Embedding(MAX_SUBCAT_1, 10)(subcat_1)\n",
    "    ebd_subcat_2 = Embedding(MAX_SUBCAT_2, 10) (subcat_2)\n",
    "\n",
    "    #Gate Recurrrent Unit\n",
    "    rnn_layer1 = GRU(16)(ebd_item_desc) \n",
    "    rnn_layer2 = GRU(8) (ebd_name)\n",
    "\n",
    "    #flatten\n",
    "    main_l = concatenate([Flatten()(ebd_brand_name),\n",
    "                          Flatten()(ebd_item_condition),\n",
    "                          Flatten()(ebd_desc_len),\n",
    "                          Flatten()(ebd_name_len),\n",
    "                          Flatten()(ebd_subcat_0),\n",
    "                          Flatten()(ebd_subcat_1),\n",
    "                          Flatten()(ebd_subcat_2),\n",
    "                          rnn_layer1,   #item description\n",
    "                          rnn_layer2,   #name description\n",
    "                          num_vars])\n",
    "\n",
    "    #FUll connect\n",
    "    main_l = Dropout(0.1)(Dense(512,\n",
    "                                kernel_initializer = 'normal',\n",
    "                                activation = 'relu')(main_l))\n",
    "    \n",
    "    main_l = Dropout(0.1)(Dense(256,\n",
    "                                kernel_initializer = 'normal',\n",
    "                                activation = 'relu')(main_l))\n",
    "    \n",
    "    main_l = Dropout(0.1)(Dense(128,\n",
    "                                kernel_initializer = 'normal',\n",
    "                                activation = 'relu')(main_l))\n",
    "\n",
    "    main_l = Dropout(0.1)(Dense(64,\n",
    "                                kernel_initializer = 'normal',\n",
    "                                activation = 'relu')(main_l))\n",
    "    \n",
    "    #output layer\n",
    "    output = Dense(1, \n",
    "                   activation = 'linear') (main_l)\n",
    "\n",
    "    #input layer\n",
    "    model = Model(  inputs=  [   name,\n",
    "                                item_desc,\n",
    "                                brand_name,\n",
    "                                item_condition,\n",
    "                                num_vars,\n",
    "                                desc_len,\n",
    "                                name_len,\n",
    "                                subcat_0,\n",
    "                                subcat_1,\n",
    "                                subcat_2\n",
    "                            ],\n",
    "                    outputs = output)\n",
    "    #set compiler\n",
    "    model.compile(  loss = 'mse',\n",
    "                    optimizer = Adam(   lr = lr,\n",
    "                                        decay = decay))\n",
    "    return model\n",
    "\n",
    "#create model\n",
    "model = new_rnn_model()\n",
    "model.summary()\n",
    "\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e00d3216",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T14:26:03.538578Z",
     "iopub.status.busy": "2022-07-21T14:26:03.538240Z",
     "iopub.status.idle": "2022-07-21T14:28:29.814973Z",
     "shell.execute_reply": "2022-07-21T14:28:29.813850Z"
    },
    "papermill": {
     "duration": 146.388993,
     "end_time": "2022-07-21T14:28:29.915767",
     "exception": false,
     "start_time": "2022-07-21T14:26:03.526774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 14:26:04.009258: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 440053200 exceeds 10% of free system memory.\n",
      "2022-07-21 14:26:04.485524: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 14:26:08.853594: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1433/1433 [==============================] - 39s 23ms/step - loss: 0.3200 - val_loss: 0.1931\n",
      "Epoch 2/3\n",
      "1433/1433 [==============================] - 34s 23ms/step - loss: 0.1877 - val_loss: 0.1973\n",
      "Epoch 3/3\n",
      "1433/1433 [==============================] - 33s 23ms/step - loss: 0.1544 - val_loss: 0.1833\n",
      "CPU times: user 1min 59s, sys: 10.5 s, total: 2min 10s\n",
      "Wall time: 2min 26s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8e3896e290>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#batch size\n",
    "BATCH_SIZE = 512 * 2\n",
    "epochs = 3\n",
    "\n",
    "#lr decay\n",
    "exp_decay = lambda init, fin, steps: (init / fin)**(1/(steps-1))-1\n",
    "steps = int(len(X_train['name']) / BATCH_SIZE) * epochs\n",
    "lr_init = 0.005\n",
    "lr_fin = 0.001\n",
    "lr_decay = exp_decay(lr_init, lr_fin, steps)\n",
    "\n",
    "#create model\n",
    "rnn_model = new_rnn_model(lr = lr_init, decay = lr_decay)\n",
    "#training model\n",
    "rnn_model.fit(  X_train,\n",
    "                Y_train,\n",
    "                epochs = epochs,\n",
    "                batch_size = BATCH_SIZE,\n",
    "                validation_data = (X_dev, Y_dev),\n",
    "                verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8c42267",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-21T14:28:30.115422Z",
     "iopub.status.busy": "2022-07-21T14:28:30.115068Z",
     "iopub.status.idle": "2022-07-21T14:28:30.121823Z",
     "shell.execute_reply": "2022-07-21T14:28:30.120456Z"
    },
    "papermill": {
     "duration": 0.111222,
     "end_time": "2022-07-21T14:28:30.125781",
     "exception": true,
     "start_time": "2022-07-21T14:28:30.014559",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%time` not found.\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the results and measure error\n",
    "%%time\n",
    "print('Evaluating the model on validation data')\n",
    "#predict the data using the trained model\n",
    "Y_dev_preds_rnn = rnn_model.predict(X_dev,\n",
    "                                    batch_size = BATCH_SIZE)\n",
    "\n",
    "#use rmlse() to find error\n",
    "print('RMSLE error:', rmsle(Y_dev,\n",
    "                            Y_dev_preds_rnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c509115",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rnn_preds = rnn_model.predict(  X_test,\n",
    "                                batch_size = BATCH_SIZE,\n",
    "                                verbose = 1)\n",
    "\n",
    "#exp transformation (eliminate the log transformation )\n",
    "rnn_preds = np.expm1(rnn_preds)\n",
    "del rnn_model\n",
    "gc.collect()\n",
    "\n",
    "stop_real = datetime.now()\n",
    "execution_time_real = stop_real - start_real\n",
    "print(execution_time_real)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 484.278188,
   "end_time": "2022-07-21T14:28:32.946751",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-07-21T14:20:28.668563",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

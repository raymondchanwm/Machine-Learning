{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d95cec3",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-06-10T06:05:06.646229Z",
     "iopub.status.busy": "2022-06-10T06:05:06.645066Z",
     "iopub.status.idle": "2022-06-10T06:05:06.658500Z",
     "shell.execute_reply": "2022-06-10T06:05:06.657746Z"
    },
    "papermill": {
     "duration": 0.021099,
     "end_time": "2022-06-10T06:05:06.661112",
     "exception": false,
     "start_time": "2022-06-10T06:05:06.640013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/cifar-10/trainLabels.csv\n",
      "/kaggle/input/cifar-10/sampleSubmission.csv\n",
      "/kaggle/input/cifar-10/test.7z\n",
      "/kaggle/input/cifar-10/train.7z\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a90cb090",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T06:05:06.670055Z",
     "iopub.status.busy": "2022-06-10T06:05:06.669332Z",
     "iopub.status.idle": "2022-06-10T06:05:11.931851Z",
     "shell.execute_reply": "2022-06-10T06:05:11.930997Z"
    },
    "papermill": {
     "duration": 5.268235,
     "end_time": "2022-06-10T06:05:11.934141",
     "exception": false,
     "start_time": "2022-06-10T06:05:06.665906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def prepare_data():\n",
    "    \"\"\"\n",
    "    prepare the data\n",
    "    Returns:\n",
    "        x_train(ndarray): #training data (50000,32,32,3)\n",
    "        x_test(ndarray) : #testing data  (10000,32,32,3) \n",
    "        y_train(ndarray): #training answer , one-hot encoded (50000,10)\n",
    "        y_test(ndarray) : #testing data answer, one-hot encoded (10000,10)\n",
    "        y_test_label (ndarray) : #\n",
    "    \"\"\"\n",
    "    \n",
    "    #load data\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    \n",
    "    #normalization\n",
    "    (x_train, x_test) = x_train.astype('float32'), x_test.astype('float32')\n",
    "    x_train, x_test = x_train/255.0, x_test/255.0\n",
    "    \n",
    "    #one-hot encoding\n",
    "    y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "224bf5ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T06:05:11.941393Z",
     "iopub.status.busy": "2022-06-10T06:05:11.940265Z",
     "iopub.status.idle": "2022-06-10T06:05:11.951883Z",
     "shell.execute_reply": "2022-06-10T06:05:11.951209Z"
    },
    "papermill": {
     "duration": 0.016726,
     "end_time": "2022-06-10T06:05:11.953528",
     "exception": false,
     "start_time": "2022-06-10T06:05:11.936802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "def make_convlayer():\n",
    "    \"\"\"\n",
    "    building model\n",
    "    \"\"\"\n",
    "    \n",
    "    #build dequential object\n",
    "    model = Sequential()\n",
    "    \n",
    "    #conv layer 1\n",
    "    model.add(Conv2D(filters = 64,\n",
    "                     kernel_size = 3,\n",
    "                     padding = 'same',\n",
    "                     activation = 'relu',\n",
    "                     input_shape = (32,32,3)))\n",
    "    \n",
    "    #2x2 pooling\n",
    "    model.add(MaxPooling2D(pool_size = 2))\n",
    "    \n",
    "    #Conv layer 2\n",
    "    model.add(Conv2D(filters = 128,\n",
    "                     kernel_size = 3,\n",
    "                     padding = 'same',\n",
    "                     activation = 'relu'))\n",
    "    \n",
    "    #2x2 pooling\n",
    "    model.add(MaxPooling2D(pool_size = 2))\n",
    "    \n",
    "    #Conv layer 3\n",
    "    model.add(Conv2D(filters = 256,\n",
    "                     kernel_size = 3,\n",
    "                     padding = 'same',\n",
    "                     activation = 'relu'))\n",
    "    \n",
    "    #2x2 pooling\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    \n",
    "    #flatten\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    #Dropout\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    #7th layer, full connect\n",
    "    model.add(Dense(512, \n",
    "                    activation = 'relu'))\n",
    "    \n",
    "    #output:\n",
    "    model.add(Dense(10,\n",
    "                    activation = 'softmax'))\n",
    "    \n",
    "    #compile, adam as optimizer\n",
    "    model.compile(loss = 'categorical_crossentropy',\n",
    "                  optimizer = optimizers.Adam(lr = 0.001),\n",
    "                  metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2429f490",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T06:05:11.959781Z",
     "iopub.status.busy": "2022-06-10T06:05:11.959467Z",
     "iopub.status.idle": "2022-06-10T06:05:11.971499Z",
     "shell.execute_reply": "2022-06-10T06:05:11.970825Z"
    },
    "papermill": {
     "duration": 0.017214,
     "end_time": "2022-06-10T06:05:11.973220",
     "exception": false,
     "start_time": "2022-06-10T06:05:11.956006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class LRHistory(Callback):\n",
    "    def on_train_begin(self, logs = {}):\n",
    "        self.acc = []\n",
    "        self.lr = []\n",
    "    def on_epoche_end(self, batch, logs = {}):\n",
    "        self.acc.append(logs.get('acc'))\n",
    "        self.lr.append(step_decay(len(self.acc)))\n",
    "        \n",
    "def step_decay(epoch):\n",
    "    \"\"\"\n",
    "    use step decay\n",
    "    return learning rate\n",
    "    \"\"\"\n",
    "    \n",
    "    initial_lrate = 0.001 #initial lrate\n",
    "    drop = 0.5            #decay rate\n",
    "    epochs_drop = 10.0   #decay after 10 times\n",
    "    lrate = initial_lrate * math.pow(drop, # \"drop\" to the power of lrate\n",
    "                                     math.floor((epoch)/epochs_drop)) \n",
    "    return lrate\n",
    "    \n",
    "def train(x_train, x_test, y_train, y_test):\n",
    "    \n",
    "    model = make_convlayer()\n",
    "    lr_history = LRHistory()\n",
    "    lrate = LearningRateScheduler(step_decay)\n",
    "    callbacks_list = [lr_history, lrate]\n",
    "    \n",
    "    #data augmentation\n",
    "    datagen = ImageDataGenerator(width_shift_range = 0.1,\n",
    "                                 height_shift_range = 0.1,\n",
    "                                 rotation_range = 10,\n",
    "                                 zoom_range = 0.1,\n",
    "                                 horizontal_flip = True)\n",
    "    #batch size\n",
    "    batch_size = 128\n",
    "    \n",
    "    #training times\n",
    "    epochs = 100\n",
    "    \n",
    "    #train\n",
    "    step_epoch = x_train.shape[0] // batch_size\n",
    "    history = model.fit(datagen.flow(x_train,\n",
    "                                     y_train,\n",
    "                                     batch_size = batch_size),\n",
    "                        steps_per_epoch = step_epoch, #steps in each batch\n",
    "                        epochs = epochs,              #training times\n",
    "                        verbose = 1,                  #output\n",
    "                        validation_data = (x_test, y_test),\n",
    "                        callbacks = callbacks_list)\n",
    "    return history, lr_history\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01dfdc57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T06:05:11.979178Z",
     "iopub.status.busy": "2022-06-10T06:05:11.978913Z",
     "iopub.status.idle": "2022-06-10T06:05:18.059282Z",
     "shell.execute_reply": "2022-06-10T06:05:18.058453Z"
    },
    "papermill": {
     "duration": 6.085747,
     "end_time": "2022-06-10T06:05:18.061415",
     "exception": false,
     "start_time": "2022-06-10T06:05:11.975668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 3s 0us/step\n",
      "170508288/170498071 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = prepare_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9c0615a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T06:05:18.076928Z",
     "iopub.status.busy": "2022-06-10T06:05:18.076096Z",
     "iopub.status.idle": "2022-06-10T07:05:08.127842Z",
     "shell.execute_reply": "2022-06-10T07:05:08.126165Z"
    },
    "papermill": {
     "duration": 3590.061993,
     "end_time": "2022-06-10T07:05:08.130420",
     "exception": false,
     "start_time": "2022-06-10T06:05:18.068427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-10 06:05:18.174561: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-10 06:05:18.277087: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-10 06:05:18.277872: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-10 06:05:18.279252: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-10 06:05:18.279602: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-10 06:05:18.280690: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-10 06:05:18.281634: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-10 06:05:20.704222: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-10 06:05:20.705109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-10 06:05:20.705794: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-10 06:05:20.706434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
      "/opt/conda/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
      "2022-06-10 06:05:21.479107: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-10 06:05:22.992420: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 36s 74ms/step - loss: 1.6144 - accuracy: 0.4080 - val_loss: 1.2188 - val_accuracy: 0.5595\n",
      "Epoch 2/100\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 1.2322 - accuracy: 0.5606 - val_loss: 1.0148 - val_accuracy: 0.6364\n",
      "Epoch 3/100\n",
      "390/390 [==============================] - 29s 73ms/step - loss: 1.0802 - accuracy: 0.6171 - val_loss: 0.8855 - val_accuracy: 0.6922\n",
      "Epoch 4/100\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.9716 - accuracy: 0.6562 - val_loss: 0.8197 - val_accuracy: 0.7105\n",
      "Epoch 5/100\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.9023 - accuracy: 0.6820 - val_loss: 0.7826 - val_accuracy: 0.7242\n",
      "Epoch 6/100\n",
      "390/390 [==============================] - 29s 73ms/step - loss: 0.8531 - accuracy: 0.7012 - val_loss: 0.7273 - val_accuracy: 0.7478\n",
      "Epoch 7/100\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.8080 - accuracy: 0.7165 - val_loss: 0.6983 - val_accuracy: 0.7589\n",
      "Epoch 8/100\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.7761 - accuracy: 0.7265 - val_loss: 0.6593 - val_accuracy: 0.7742\n",
      "Epoch 9/100\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.7391 - accuracy: 0.7393 - val_loss: 0.6454 - val_accuracy: 0.7817\n",
      "Epoch 10/100\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.7118 - accuracy: 0.7505 - val_loss: 0.6307 - val_accuracy: 0.7840\n",
      "Epoch 11/100\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.6380 - accuracy: 0.7759 - val_loss: 0.5994 - val_accuracy: 0.7935\n",
      "Epoch 12/100\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.6197 - accuracy: 0.7825 - val_loss: 0.6101 - val_accuracy: 0.7858\n",
      "Epoch 13/100\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.6052 - accuracy: 0.7878 - val_loss: 0.6317 - val_accuracy: 0.7839\n",
      "Epoch 14/100\n",
      "390/390 [==============================] - 29s 73ms/step - loss: 0.5892 - accuracy: 0.7925 - val_loss: 0.5499 - val_accuracy: 0.8113\n",
      "Epoch 15/100\n",
      "390/390 [==============================] - 28s 71ms/step - loss: 0.5761 - accuracy: 0.7969 - val_loss: 0.5548 - val_accuracy: 0.8073\n",
      "Epoch 16/100\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.5709 - accuracy: 0.7994 - val_loss: 0.5660 - val_accuracy: 0.8042\n",
      "Epoch 17/100\n",
      "390/390 [==============================] - 29s 73ms/step - loss: 0.5580 - accuracy: 0.8036 - val_loss: 0.5555 - val_accuracy: 0.8059\n",
      "Epoch 18/100\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.5447 - accuracy: 0.8071 - val_loss: 0.5309 - val_accuracy: 0.8181\n",
      "Epoch 19/100\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.5338 - accuracy: 0.8112 - val_loss: 0.5346 - val_accuracy: 0.8208\n",
      "Epoch 20/100\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.5223 - accuracy: 0.8162 - val_loss: 0.5555 - val_accuracy: 0.8141\n",
      "Epoch 21/100\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.4928 - accuracy: 0.8270 - val_loss: 0.4990 - val_accuracy: 0.8296\n",
      "Epoch 22/100\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.4765 - accuracy: 0.8320 - val_loss: 0.4943 - val_accuracy: 0.8361\n",
      "Epoch 23/100\n",
      "390/390 [==============================] - 29s 73ms/step - loss: 0.4694 - accuracy: 0.8323 - val_loss: 0.4893 - val_accuracy: 0.8376\n",
      "Epoch 24/100\n",
      "390/390 [==============================] - 31s 79ms/step - loss: 0.4686 - accuracy: 0.8363 - val_loss: 0.5147 - val_accuracy: 0.8259\n",
      "Epoch 25/100\n",
      "390/390 [==============================] - 30s 77ms/step - loss: 0.4570 - accuracy: 0.8382 - val_loss: 0.5157 - val_accuracy: 0.8257\n",
      "Epoch 26/100\n",
      "390/390 [==============================] - 29s 73ms/step - loss: 0.4531 - accuracy: 0.8418 - val_loss: 0.5170 - val_accuracy: 0.8262\n",
      "Epoch 27/100\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.4486 - accuracy: 0.8418 - val_loss: 0.4880 - val_accuracy: 0.8372\n",
      "Epoch 28/100\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.4408 - accuracy: 0.8435 - val_loss: 0.4762 - val_accuracy: 0.8403\n",
      "Epoch 29/100\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.4414 - accuracy: 0.8447 - val_loss: 0.4810 - val_accuracy: 0.8411\n",
      "Epoch 30/100\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.4318 - accuracy: 0.8468 - val_loss: 0.4965 - val_accuracy: 0.8329\n",
      "Epoch 31/100\n",
      "390/390 [==============================] - 28s 72ms/step - loss: 0.4109 - accuracy: 0.8551 - val_loss: 0.4829 - val_accuracy: 0.8399\n",
      "Epoch 32/100\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.4095 - accuracy: 0.8548 - val_loss: 0.4923 - val_accuracy: 0.8368\n",
      "Epoch 33/100\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.4075 - accuracy: 0.8566 - val_loss: 0.4727 - val_accuracy: 0.8429\n",
      "Epoch 34/100\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.4029 - accuracy: 0.8564 - val_loss: 0.5017 - val_accuracy: 0.8349\n",
      "Epoch 35/100\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.3977 - accuracy: 0.8609 - val_loss: 0.4976 - val_accuracy: 0.8365\n",
      "Epoch 36/100\n",
      "390/390 [==============================] - 29s 73ms/step - loss: 0.3990 - accuracy: 0.8586 - val_loss: 0.4945 - val_accuracy: 0.8351\n",
      "Epoch 37/100\n",
      "390/390 [==============================] - 29s 73ms/step - loss: 0.3991 - accuracy: 0.8601 - val_loss: 0.4727 - val_accuracy: 0.8436\n",
      "Epoch 38/100\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.3938 - accuracy: 0.8613 - val_loss: 0.4800 - val_accuracy: 0.8419\n",
      "Epoch 39/100\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.3883 - accuracy: 0.8634 - val_loss: 0.4921 - val_accuracy: 0.8381\n",
      "Epoch 40/100\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.3860 - accuracy: 0.8633 - val_loss: 0.4829 - val_accuracy: 0.8396\n",
      "Epoch 41/100\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.3758 - accuracy: 0.8662 - val_loss: 0.4801 - val_accuracy: 0.8431\n",
      "Epoch 42/100\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.3781 - accuracy: 0.8661 - val_loss: 0.4750 - val_accuracy: 0.8431\n",
      "Epoch 43/100\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.3725 - accuracy: 0.8682 - val_loss: 0.4783 - val_accuracy: 0.8418\n",
      "Epoch 44/100\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.3723 - accuracy: 0.8675 - val_loss: 0.4795 - val_accuracy: 0.8430\n",
      "Epoch 45/100\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.3666 - accuracy: 0.8702 - val_loss: 0.4857 - val_accuracy: 0.8411\n",
      "Epoch 46/100\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.3675 - accuracy: 0.8699 - val_loss: 0.4819 - val_accuracy: 0.8427\n",
      "Epoch 47/100\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.3710 - accuracy: 0.8677 - val_loss: 0.4723 - val_accuracy: 0.8459\n",
      "Epoch 48/100\n",
      "390/390 [==============================] - 28s 73ms/step - loss: 0.3638 - accuracy: 0.8702 - val_loss: 0.4775 - val_accuracy: 0.8427\n",
      "Epoch 49/100\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.3622 - accuracy: 0.8720 - val_loss: 0.4826 - val_accuracy: 0.8387\n",
      "Epoch 50/100\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.3659 - accuracy: 0.8716 - val_loss: 0.4709 - val_accuracy: 0.8464\n",
      "Epoch 51/100\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.3595 - accuracy: 0.8730 - val_loss: 0.4693 - val_accuracy: 0.8447\n",
      "Epoch 52/100\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.3582 - accuracy: 0.8736 - val_loss: 0.4769 - val_accuracy: 0.8428\n",
      "Epoch 53/100\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.3596 - accuracy: 0.8723 - val_loss: 0.4727 - val_accuracy: 0.8424\n",
      "Epoch 54/100\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.3538 - accuracy: 0.8757 - val_loss: 0.4751 - val_accuracy: 0.8439\n",
      "Epoch 55/100\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.3514 - accuracy: 0.8755 - val_loss: 0.4739 - val_accuracy: 0.8447\n",
      "Epoch 56/100\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.3540 - accuracy: 0.8763 - val_loss: 0.4795 - val_accuracy: 0.8430\n",
      "Epoch 57/100\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.3518 - accuracy: 0.8752 - val_loss: 0.4708 - val_accuracy: 0.8437\n",
      "Epoch 58/100\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.3497 - accuracy: 0.8771 - val_loss: 0.4724 - val_accuracy: 0.8459\n",
      "Epoch 59/100\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.3560 - accuracy: 0.8726 - val_loss: 0.4750 - val_accuracy: 0.8419\n",
      "Epoch 60/100\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.3511 - accuracy: 0.8746 - val_loss: 0.4704 - val_accuracy: 0.8448\n",
      "Epoch 61/100\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.3479 - accuracy: 0.8769 - val_loss: 0.4745 - val_accuracy: 0.8430\n",
      "Epoch 62/100\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.3485 - accuracy: 0.8774 - val_loss: 0.4759 - val_accuracy: 0.8429\n",
      "Epoch 63/100\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.3463 - accuracy: 0.8782 - val_loss: 0.4696 - val_accuracy: 0.8452\n",
      "Epoch 64/100\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.3446 - accuracy: 0.8781 - val_loss: 0.4664 - val_accuracy: 0.8462\n",
      "Epoch 65/100\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.3472 - accuracy: 0.8763 - val_loss: 0.4760 - val_accuracy: 0.8460\n",
      "Epoch 66/100\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.3460 - accuracy: 0.8788 - val_loss: 0.4609 - val_accuracy: 0.8477\n",
      "Epoch 67/100\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.3450 - accuracy: 0.8796 - val_loss: 0.4796 - val_accuracy: 0.8437\n",
      "Epoch 68/100\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.3472 - accuracy: 0.8761 - val_loss: 0.4702 - val_accuracy: 0.8466\n",
      "Epoch 69/100\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.3470 - accuracy: 0.8775 - val_loss: 0.4687 - val_accuracy: 0.8469\n",
      "Epoch 70/100\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.3457 - accuracy: 0.8778 - val_loss: 0.4770 - val_accuracy: 0.8439\n",
      "Epoch 71/100\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.3437 - accuracy: 0.8792 - val_loss: 0.4688 - val_accuracy: 0.8459\n",
      "Epoch 72/100\n",
      "390/390 [==============================] - 29s 76ms/step - loss: 0.3445 - accuracy: 0.8781 - val_loss: 0.4713 - val_accuracy: 0.8457\n",
      "Epoch 73/100\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.3430 - accuracy: 0.8801 - val_loss: 0.4674 - val_accuracy: 0.8466\n",
      "Epoch 74/100\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.3427 - accuracy: 0.8793 - val_loss: 0.4739 - val_accuracy: 0.8455\n",
      "Epoch 75/100\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.3449 - accuracy: 0.8766 - val_loss: 0.4649 - val_accuracy: 0.8483\n",
      "Epoch 76/100\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.3369 - accuracy: 0.8793 - val_loss: 0.4767 - val_accuracy: 0.8444\n",
      "Epoch 77/100\n",
      "390/390 [==============================] - 29s 74ms/step - loss: 0.3437 - accuracy: 0.8783 - val_loss: 0.4688 - val_accuracy: 0.8469\n",
      "Epoch 78/100\n",
      "390/390 [==============================] - 30s 77ms/step - loss: 0.3415 - accuracy: 0.8791 - val_loss: 0.4707 - val_accuracy: 0.8451\n",
      "Epoch 79/100\n",
      "390/390 [==============================] - 29s 76ms/step - loss: 0.3428 - accuracy: 0.8800 - val_loss: 0.4726 - val_accuracy: 0.8450\n",
      "Epoch 80/100\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.3388 - accuracy: 0.8806 - val_loss: 0.4716 - val_accuracy: 0.8464\n",
      "Epoch 81/100\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.3399 - accuracy: 0.8800 - val_loss: 0.4722 - val_accuracy: 0.8454\n",
      "Epoch 82/100\n",
      "390/390 [==============================] - 30s 78ms/step - loss: 0.3418 - accuracy: 0.8801 - val_loss: 0.4683 - val_accuracy: 0.8462\n",
      "Epoch 83/100\n",
      "390/390 [==============================] - 29s 76ms/step - loss: 0.3431 - accuracy: 0.8797 - val_loss: 0.4715 - val_accuracy: 0.8464\n",
      "Epoch 84/100\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.3434 - accuracy: 0.8793 - val_loss: 0.4732 - val_accuracy: 0.8458\n",
      "Epoch 85/100\n",
      "390/390 [==============================] - 30s 77ms/step - loss: 0.3376 - accuracy: 0.8798 - val_loss: 0.4691 - val_accuracy: 0.8469\n",
      "Epoch 86/100\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.3383 - accuracy: 0.8796 - val_loss: 0.4734 - val_accuracy: 0.8452\n",
      "Epoch 87/100\n",
      "390/390 [==============================] - 29s 76ms/step - loss: 0.3381 - accuracy: 0.8810 - val_loss: 0.4691 - val_accuracy: 0.8458\n",
      "Epoch 88/100\n",
      "390/390 [==============================] - 30s 77ms/step - loss: 0.3397 - accuracy: 0.8807 - val_loss: 0.4722 - val_accuracy: 0.8456\n",
      "Epoch 89/100\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.3373 - accuracy: 0.8808 - val_loss: 0.4722 - val_accuracy: 0.8460\n",
      "Epoch 90/100\n",
      "390/390 [==============================] - 29s 75ms/step - loss: 0.3424 - accuracy: 0.8778 - val_loss: 0.4702 - val_accuracy: 0.8461\n",
      "Epoch 91/100\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.3365 - accuracy: 0.8834 - val_loss: 0.4723 - val_accuracy: 0.8456\n",
      "Epoch 92/100\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.3406 - accuracy: 0.8793 - val_loss: 0.4715 - val_accuracy: 0.8459\n",
      "Epoch 93/100\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.3381 - accuracy: 0.8803 - val_loss: 0.4712 - val_accuracy: 0.8465\n",
      "Epoch 94/100\n",
      "390/390 [==============================] - 29s 76ms/step - loss: 0.3407 - accuracy: 0.8784 - val_loss: 0.4711 - val_accuracy: 0.8465\n",
      "Epoch 95/100\n",
      "390/390 [==============================] - 30s 78ms/step - loss: 0.3437 - accuracy: 0.8789 - val_loss: 0.4679 - val_accuracy: 0.8470\n",
      "Epoch 96/100\n",
      "390/390 [==============================] - 30s 77ms/step - loss: 0.3409 - accuracy: 0.8805 - val_loss: 0.4692 - val_accuracy: 0.8472\n",
      "Epoch 97/100\n",
      "390/390 [==============================] - 30s 78ms/step - loss: 0.3393 - accuracy: 0.8802 - val_loss: 0.4706 - val_accuracy: 0.8467\n",
      "Epoch 98/100\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.3359 - accuracy: 0.8806 - val_loss: 0.4724 - val_accuracy: 0.8466\n",
      "Epoch 99/100\n",
      "390/390 [==============================] - 30s 76ms/step - loss: 0.3401 - accuracy: 0.8803 - val_loss: 0.4717 - val_accuracy: 0.8456\n",
      "Epoch 100/100\n",
      "390/390 [==============================] - 30s 77ms/step - loss: 0.3387 - accuracy: 0.8813 - val_loss: 0.4695 - val_accuracy: 0.8464\n",
      "CPU times: user 51min 45s, sys: 56.2 s, total: 52min 41s\n",
      "Wall time: 59min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history, lr_history = train(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e0685f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T07:05:13.664378Z",
     "iopub.status.busy": "2022-06-10T07:05:13.663927Z",
     "iopub.status.idle": "2022-06-10T07:05:14.079281Z",
     "shell.execute_reply": "2022-06-10T07:05:14.078284Z"
    },
    "papermill": {
     "duration": 3.386387,
     "end_time": "2022-06-10T07:05:14.080898",
     "exception": true,
     "start_time": "2022-06-10T07:05:10.694511",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'figsize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22/2118607353.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#set printing area\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m            \u001b[0;31m#adjust the size of the figures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m#print on the 2x1 gridlines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m                    \u001b[0;31m#plot accuray and validatlr_historyion accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'figsize' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x_range = list(range(1,len(lr_history.lr)+1))\n",
    "\n",
    "#set printing area\n",
    "plt.figure(figsize(15,10))            #adjust the size of the figures\n",
    "plt.subplots(adjust(wspace=0.2))      #print on the 2x1 gridlines\n",
    "plt.subplot(2,1,1)                    #plot accuray and validatlr_historyion accuracy\n",
    "plt.plot(x_range, history['accuary'],\n",
    "         label = 'train', linestyle = '--')\n",
    "plt.plot(x_range, history.history['val_accuracy'],\n",
    "         label = 'Val Acc')\n",
    "plt.legend()                          #show legend\n",
    "plt.grid()                            #show grid line\n",
    "plt.xlabel('Epoch')                   #show x axis label\n",
    "plt.ylabel('Acc')                     #show y axis label\n",
    "\n",
    "#plt under 2x1 gridline\n",
    "plt.subplot(2,1,2)                    #plot learning rate\n",
    "plt.plot(x_range, lr_history.lr, lebel = 'Learning Rate')\n",
    "plt.legend()                          #plot legend\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3621.081499,
   "end_time": "2022-06-10T07:05:19.722049",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-10T06:04:58.640550",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
